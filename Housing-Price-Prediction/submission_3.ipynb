{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2803064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf922091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "768dab7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Drop Columns with Too Much Missing Data (Optional but Practical)\n",
    "cols_to_drop = ['Alley', 'PoolQC', 'Fence', 'MiscFeature', 'FireplaceQu', 'Id']\n",
    "train_df.drop(columns=cols_to_drop, inplace=True)\n",
    "test_df.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bff76715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Log Transform Target\n",
    "y_log = np.log1p(train_df[\"SalePrice\"])\n",
    "X = train_df.drop(\"SalePrice\", axis=1)\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6ebf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine for consistent preprocessing\n",
    "X_full = pd.concat([X, X_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29587dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Identify Categorical and Numerical Columns\n",
    "categorical_cols = X_full.select_dtypes(include=['object']).columns.tolist()\n",
    "numerical_cols = X_full.select_dtypes(include=['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b58b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build Preprocessing Pipelines\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_pipeline, numerical_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b363c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Split Train/Validation Set Again (before CV)\n",
    "X_train, X_val, y_train_log, y_val_log = train_test_split(\n",
    "    X, y_log, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "065dd5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Model Pipeline with XGBoost\n",
    "xgb_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(random_state=42))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3abfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Hyperparameter Grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [200, 500],\n",
    "    'regressor__learning_rate': [0.01, 0.05],\n",
    "    'regressor__max_depth': [3, 4, 5],\n",
    "    'regressor__subsample': [0.8, 1.0],\n",
    "    'regressor__colsample_bytree': [0.7, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa2f95ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Grid Search with Cross Validation\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, scoring='neg_mean_squared_error',\n",
    "                           cv=5, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train_log)\n",
    "\n",
    "# Best model after grid search\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9143df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE (log scale): 0.1255\n",
      "Best Parameters: {'regressor__colsample_bytree': 0.7, 'regressor__learning_rate': 0.05, 'regressor__max_depth': 3, 'regressor__n_estimators': 500, 'regressor__subsample': 0.8}\n",
      "Validation RMSE (original scale): 25068.40\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Evaluate on Validation Set\n",
    "y_pred_log = best_model.predict(X_val)\n",
    "rmse = np.sqrt(mean_squared_error(y_val_log, y_pred_log))\n",
    "print(f\"Validation RMSE (log scale): {rmse:.4f}\")\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Inverse log transform\n",
    "y_pred_original = np.expm1(y_pred_log)\n",
    "y_val_original = np.expm1(y_val_log)\n",
    "rmse_original = np.sqrt(mean_squared_error(y_val_original, y_pred_original))\n",
    "print(f\"Validation RMSE (original scale): {rmse_original:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57c3cefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE: 0.1204 ± 0.0115\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Cross-Validation Analysis\n",
    "cv_scores = cross_val_score(best_model, X, y_log, scoring='neg_mean_squared_error', cv=KFold(5))\n",
    "cv_rmse = np.sqrt(-cv_scores)\n",
    "print(f\"Cross-Validation RMSE: {cv_rmse.mean():.4f} ± {cv_rmse.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d92d89b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "submission3.csv created\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Predict on Test Set\n",
    "test_ids = pd.read_csv(\"test.csv\")[\"Id\"]\n",
    "final_predictions_log = best_model.predict(X_test)\n",
    "final_predictions = np.expm1(final_predictions_log)\n",
    "\n",
    "# Create Submission File\n",
    "submission = pd.DataFrame({\n",
    "    \"Id\": test_ids,\n",
    "    \"SalePrice\": final_predictions\n",
    "})\n",
    "\n",
    "submission.to_csv(\"submission3.csv\", index=False)\n",
    "print(\"submission3.csv created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
